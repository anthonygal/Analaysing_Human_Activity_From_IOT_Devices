{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade scikit-learn\n",
    "# ! pip install pydotplus\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Imports des modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agaltier/anaconda3/lib/python3.6/site-packages/sklearn/externals/six.py:31: DeprecationWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "import seaborn as sns\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "from IPython.display import Image  \n",
    "import pydotplus\n",
    "\n",
    "from statistics import mean \n",
    "\n",
    "from datetime import datetime\n",
    "import ast\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#CLASSIFIEURS\n",
    "from sklearn import discriminant_analysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.externals.six import StringIO  \n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "\n",
    "#CLUSTERING\n",
    "from sklearn.cluster import KMeans\n",
    "import scipy.cluster.hierarchy as shc\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Lecture des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_dates = ['DATE']\n",
    "glasses_df = pd.read_csv(\"./donnees/glasses.csv\", parse_dates= parse_dates)\n",
    "parse_dates = ['timestamp']\n",
    "smartwatch_df = pd.read_csv(\"./donnees/smartwatch.csv\", parse_dates= parse_dates)\n",
    "smartphone_df = pd.read_csv(\"./donnees/smartphone.csv\", parse_dates= parse_dates)\n",
    "parse_dates = ['to', 'from']\n",
    "report_df = pd.read_csv(\"./donnees/report.csv\", parse_dates= parse_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "ax = sns.countplot(x=\"source\", data=smartphone_df[smartphone_df.source.isin(['step_detector',\n",
    " 'audio',\n",
    " 'accelerometer',\n",
    " 'pressure',\n",
    " 'light',\n",
    " 'wifi',\n",
    " 'bluetooth'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "ax = sns.countplot(x=\"source\", data=smartwatch_df[smartwatch_df.source.isin(['battery',\n",
    "'accelerometer',\n",
    "'pressure',\n",
    "'heart_rate',\n",
    "'step_detector'])]).set_title('Nombre de mesures par source')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Preparation des donnees Smartwatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "\n",
    "data['heart_rate'] = [None] * len(smartwatch_df)\n",
    "\n",
    "for index, row in tqdm(smartwatch_df.iterrows(), total=len(smartwatch_df)):\n",
    "    \n",
    "    \n",
    "    values = [ float(x) for x in ast.literal_eval(row['values']) ]\n",
    "\n",
    "    if row['source'] == 'heart_rate':\n",
    "        data['heart_rate'][index] = values[0]\n",
    "\n",
    "\n",
    "smartwatch_df[\"heart_rate\"] = data['heart_rate']\n",
    "\n",
    "resampling_functions = {\n",
    "    'heart_rate': np.mean,\n",
    "}\n",
    "\n",
    "smartwatch_df = smartwatch_df[ \n",
    "                                smartwatch_df['heart_rate'].notnull()  \n",
    "    \n",
    "                             ]\n",
    "\n",
    "smartwatch_df = smartwatch_df.set_index('timestamp')\n",
    "smartwatch_df = smartwatch_df['heart_rate']\n",
    "smartwatch_df = smartwatch_df.resample('min').agg(resampling_functions)\n",
    "smartwatch_df = smartwatch_df.dropna()\n",
    "smartwatch_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "\n",
    "data['audio'] = [None] * len(smartphone_df)\n",
    "data['steps'] = [None] * len(smartphone_df)\n",
    "data['wifi'] = [None] * len(smartphone_df)\n",
    "data['accelerometer'] = [None] * len(smartphone_df)\n",
    "\n",
    "\n",
    "for index, row in tqdm(smartphone_df.iterrows(), total=len(smartphone_df)):\n",
    "    \n",
    "    if row['source'] != 'activity':\n",
    "        values = [ float(x) for x in ast.literal_eval(row['values']) ]\n",
    "\n",
    "        if row['source'] == 'audio':\n",
    "            data['audio'][index] = mean(values)\n",
    "\n",
    "        if row['source'] == 'step_detector':\n",
    "            data['steps'][index] = values[0]\n",
    "\n",
    "        if row['source'] == 'accelerometer':\n",
    "            data['accelerometer'][index] = (sum([x**2 for x in values]))**0.5\n",
    "\n",
    "        if row['source'] == 'wifi':\n",
    "            data['wifi'][index] = len(values)\n",
    "\n",
    "smartphone_df[\"audio\"] = data['audio']\n",
    "smartphone_df[\"wifi\"] = data['wifi']\n",
    "smartphone_df[\"steps\"] = data['steps']\n",
    "smartphone_df[\"accelerometer\"] = data['accelerometer']\n",
    "\n",
    "\n",
    "resampling_functions = {\n",
    "    'audio': np.mean,\n",
    "    'wifi': np.mean,\n",
    "    'steps': np.sum,\n",
    "    'accelerometer': np.mean\n",
    "}\n",
    "\n",
    "smartphone_df = smartphone_df[ \n",
    "                    smartphone_df['audio'].notnull() | \n",
    "                    smartphone_df['wifi'].notnull() | \n",
    "                    smartphone_df['steps'].notnull() |\n",
    "                    smartphone_df['accelerometer'].notnull()\n",
    "                             ]\n",
    "\n",
    "smartphone_df = smartphone_df.set_index('timestamp')\n",
    "smartphone_df = smartphone_df[['audio','wifi', 'steps', 'accelerometer']]\n",
    "smartphone_df = smartphone_df.resample('min').agg(resampling_functions)\n",
    "smartphone_df['steps'].fillna(0.0, inplace=True)\n",
    "smartphone_df = smartphone_df.dropna()\n",
    "smartphone_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Jointure des datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = smartphone_df.join(smartwatch_df, lsuffix='_sp', rsuffix='_sw')\n",
    "df = df.reset_index(level=0)\n",
    "df = df.drop('level_0', axis = 1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "data['activity_index'] = [None] * len(df)\n",
    "data['activity_type'] = [None] * len(df)\n",
    "\n",
    "i=0\n",
    "for index, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    for report_index, report_row in report_df.iterrows():\n",
    "        if (index >= report_row['from']) & (index < report_row['to']):\n",
    "            data['activity_type'][i] = report_row['activity_type']\n",
    "    i=i+1\n",
    "\n",
    "df[\"activity_type\"] = data['activity_type']\n",
    "df = df.dropna()\n",
    "\n",
    "# df['hour'] = pd.Series(list(df.index)).dt.hour.tolist()\n",
    "\n",
    "df['hour'] = df.index.hour\n",
    "add_var = pd.get_dummies(df['hour'], prefix='hour', drop_first=True)\n",
    "df = df.join(add_var)\n",
    "df = df.drop(columns=['hour'])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Exploration des donnees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,5))\n",
    "ax = sns.countplot(x=\"activity_type\", data=df).set_title('Nombre de mesures par types d`activité')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(df.index[df['activity_type'] == 'At home'], axis = 0)\n",
    "df = df.drop(df.index[df['activity_type'] == 'Walking&party'], axis = 0)\n",
    "for activity_type in df['activity_type'].unique():\n",
    "    if len(df[df['activity_type'] == activity_type])<30:\n",
    "        df = df.drop(df.index[df['activity_type'] == activity_type], axis = 0)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,5))\n",
    "ax = sns.countplot(x=\"activity_type\", data=df).set_title('Nombre de mesures par types d`activité')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = [\n",
    "    'audio',\n",
    "    'wifi',\n",
    "    'steps',\n",
    "    'accelerometer',\n",
    "    'heart_rate',\n",
    "#     'hour',\n",
    "    'hour_10',\n",
    "    'hour_11',\n",
    "    'hour_12',\n",
    "    'hour_13',\n",
    "    'hour_14',\n",
    "    'hour_15',\n",
    "    'hour_16',\n",
    "    'hour_17',\n",
    "    'hour_18',\n",
    "    'hour_19',\n",
    "    'hour_21'\n",
    "]\n",
    "\n",
    "# Centrage reduction des donnees quantitatives\n",
    "normal_scaler = preprocessing.StandardScaler()\n",
    "normal_scaler_fit = normal_scaler.fit(df[variables])\n",
    "normal = normal_scaler_fit.transform(df[variables])\n",
    "\n",
    "# X et Y: entrees et sorties du modele\n",
    "\n",
    "X = pd.DataFrame(normal, columns=variables)\n",
    "\n",
    "y = df['activity_type']\n",
    "\n",
    "df_normal = pd.DataFrame(normal, columns=variables)\n",
    "df_normal['activity_type'] = df['activity_type'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[variables].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normal.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for variable in [\n",
    "                    'audio',\n",
    "                    'wifi',\n",
    "                    'steps',\n",
    "                    'accelerometer',\n",
    "                    'heart_rate'\n",
    "                ]:\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(15,5))\n",
    "    sns.set(style=\"ticks\", color_codes=True)\n",
    "    sns.boxplot(x=\"activity_type\", y=variable, data=df, showfliers=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.  Corrélations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrice de correlation\n",
    "corr = X[[\n",
    "            'audio',\n",
    "            'wifi',\n",
    "            'steps',\n",
    "            'accelerometer',\n",
    "            'heart_rate'\n",
    "                ]].corr()\n",
    "\n",
    "# Pour n'afficher que la partie inferieure de la matrice\n",
    "mask = np.zeros_like(corr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# Afficher la heatmap\n",
    "f, ax = plt.subplots(figsize=(4, 4))\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.  Analyse par Composantes Principales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 5\n",
    "pca = PCA(n_components = n_components)\n",
    "X_pca = pca.fit_transform(X[[\n",
    "                    'audio',\n",
    "                    'wifi',\n",
    "                    'steps',\n",
    "                    'accelerometer',\n",
    "                    'heart_rate'\n",
    "                ]])\n",
    "\n",
    "sns.scatterplot(X_pca[:, 0], X_pca[:, 2])\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(X_pca[:, 0], X_pca[:, 1],  X_pca[:, 2])\n",
    "plt.show()\n",
    "\n",
    "print(' ')\n",
    "print('Explained variances:')\n",
    "print(pca.explained_variance_ratio_.tolist())\n",
    "pd.Series(pca.explained_variance_ratio_.tolist()).plot(kind=\"bar\", title= \"Explained variance of each PC\")\n",
    "print(' ')\n",
    "print('Sum of explained variances: ' + str(sum(pca.explained_variance_ratio_.tolist())))\n",
    "print(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sans l'ACP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# activites = ['Eat']\n",
    "# labels = []\n",
    "# for activity_type in list(y['activity_type']):\n",
    "#     if activity_type in activites:\n",
    "#         labels.append(1)\n",
    "#     else:\n",
    "#         labels.append(0)\n",
    "\n",
    "labels = y['activity_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(labels.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.3, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\n",
    "    \"Nearest Neighbors\",\n",
    "    \"Decision Tree\", \n",
    "    \"Random Forest\"\n",
    "]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(1),\n",
    "    DecisionTreeClassifier(max_depth=10),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    ]\n",
    "\n",
    "for name, clf in zip(names, classifiers):\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    score = clf.score(X_test, y_test)\n",
    "    print(name + ' score: ' + str(round(score, 2)))\n",
    "\n",
    "    accuracy = cross_val_score(clf, X, labels, scoring='accuracy', cv = 15)\n",
    "    print(accuracy)\n",
    "    #get the mean of each fold \n",
    "    print(\"Accuracy of Model with Cross Validation is:\",accuracy.mean() * 100)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Avec l'ACP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_pca, labels, test_size=0.2, random_state=21)\n",
    "\n",
    "for name, clf in zip(names, classifiers):\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    score = clf.score(X_test, y_test)\n",
    "    print(name + ' score: ' + str(round(score, 2)))\n",
    "    \n",
    "    accuracy = cross_val_score(clf, X, labels, scoring='accuracy', cv = 15)\n",
    "    print(accuracy)\n",
    "    #get the mean of each fold \n",
    "    print(\"Accuracy of Model with Cross Validation is:\",accuracy.mean() * 100)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree = DecisionTreeClassifier(max_depth=3).fit(X_train, y_train)\n",
    "\n",
    "dot_data = StringIO()\n",
    "export_graphviz(dtree, out_file=dot_data,  \n",
    "                filled=True, rounded=True,\n",
    "                special_characters=True)\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
